# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'fer_15_3_2021.ui'
#
# Created by: PyQt5 UI code generator 5.15.2
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtCore import *
from PyQt5.QtWidgets import *
from PyQt5.QtGui import *
from PyQt5.QtChart import *
import cv2
import numpy as np
import datetime
import os.path

from keras.models import model_from_json
from keras.preprocessing import image

# load model
model = model_from_json(open("fer.json", "r").read())
# load weights
model.load_weights('fer.h5')

face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')



class Ui_OutputDialog(object):
    def setupUi(self, OutputDialog):
        OutputDialog.setObjectName("OutputDialog")       
        OutputDialog.resize(1240, 480)
        OutputDialog.setMinimumSize(QtCore.QSize(0, 0))
        OutputDialog.setMaximumSize(QtCore.QSize(1240, 480))
        font = QtGui.QFont()
        font.setFamily("Calibri")
        font.setBold(True)
        font.setWeight(75)
        OutputDialog.setFont(font)
        icon = QtGui.QIcon()
        icon.addPixmap(QtGui.QPixmap(":/icon/icon.png"), QtGui.QIcon.Normal, QtGui.QIcon.Off)
        OutputDialog.setWindowIcon(icon)
        self.imgLabel = QtWidgets.QLabel(OutputDialog)
        self.imgLabel.setGeometry(QtCore.QRect(8, 20, 600, 300))
        self.imgLabel.setMaximumSize(QtCore.QSize(600, 300))
        self.imgLabel.setText("")
        self.imgLabel.setObjectName("imgLabel")

        
        images = []
        self.class_names = []
        self.encode_list = []

        self.coverImg=cv2.imread("c3.jpg")
        #print("hello..")
        #print(self.coverImg)
        

        
        
        self.horizontalLayoutWidget = QtWidgets.QWidget(OutputDialog)
        self.horizontalLayoutWidget.setGeometry(QtCore.QRect(60, 360, 421, 80))
        self.horizontalLayoutWidget.setObjectName("horizontalLayoutWidget")
        self.horizontalLayout = QtWidgets.QHBoxLayout(self.horizontalLayoutWidget)
        self.horizontalLayout.setContentsMargins(0, 0, 0, 0)
        self.horizontalLayout.setObjectName("horizontalLayout")
        self.choosebutton = QtWidgets.QPushButton(self.horizontalLayoutWidget)
        self.choosebutton.setObjectName("choosebutton")

        self.filename =""

        self.HappyCount = 0
        self.SadCount = 0
        self.AngryCount = 0
        self.FearCount = 0
        self.DisgustCount = 0
        self.SurpriseCount = 0
        self.NeutralCount = 0
        self.ContemptCount = 0
        self.frame_count = 0

        self.choosebutton.clicked.connect(self.chooseFile_)
        
        print(self.filename)
                
        self.horizontalLayout.addWidget(self.choosebutton)
        self.startbutton = QtWidgets.QPushButton(self.horizontalLayoutWidget)
        self.startbutton.setObjectName("startbutton")
        self.startbutton.clicked.connect(self.startButton_)
        
        self.horizontalLayout.addWidget(self.startbutton)
        self.stopbutton = QtWidgets.QPushButton(self.horizontalLayoutWidget)
        self.stopbutton.setObjectName("stopbutton")
        self.stopbutton.clicked.connect(self.stopButton_)
        
        self.horizontalLayout.addWidget(self.stopbutton)
        
        self.graphicsView = QChartView(OutputDialog)
        self.graphicsView.setGeometry(QtCore.QRect(550, 10, 691, 321))
        self.graphicsView.setObjectName("graphicsView")
        
        self.result = QtWidgets.QLabel(OutputDialog)
        self.result.setGeometry(QtCore.QRect(560, 360, 291, 81))
        self.result.setObjectName("result")

        self.retranslateUi(OutputDialog)
        QtCore.QMetaObject.connectSlotsByName(OutputDialog)
        self.displayImage(self.coverImg, self.encode_list, self.class_names, 1)

    def retranslateUi(self, OutputDialog):
        _translate = QtCore.QCoreApplication.translate
        OutputDialog.setWindowTitle(_translate("OutputDialog", "Output Window"))
        self.choosebutton.setText(_translate("OutputDialog", "choose"))
        self.startbutton.setText(_translate("OutputDialog", "start"))
        self.stopbutton.setText(_translate("OutputDialog", "stop"))
        self.result.setText(_translate("OutputDialog", "Result will be shown here"))
        
    def chooseFile_(self):
		#file choosing
        print('getting...') 
        self.filename=""
        self.filename, dummy = QFileDialog.getOpenFileName(self.choosebutton, "open video file.", '~/desktop', "video files (*.mp4)")
	    
    def startButton_(self):
		#startButton
        self.stop=False
        self.startVideo()
        
		
    def stopButton_(self):
		#stop button
        #self.filename=""
        self.stop=True
        he="jj"

    @pyqtSlot()
    def startVideo(self, camera_name=""):
        """
        :param camera_name: link of camera or usb camera
        :return:
        """
        if self.stop:
            return
        
        videoFile = self.filename
        
        if len(videoFile) == 1:
        	return
        else:
        	self.capture = cv2.VideoCapture(videoFile)
        self.timer = QtCore.QTimer()  # Create Timer
        #path = 'ImagesAttendance'
        #if not os.path.exists(path):
        #    os.mkdir(path)
        # known face encoding and known face name list
        #attendance_list = os.listdir(path)
        
        #print(type(self.capture))
        
        
        
        self.timer.timeout.connect(self.update_frame)  # Connect timeout to the output function
        self.timer.start(40)  # emit the timeout() signal at x=40ms

    def update_frame(self):
        ret, self.image = self.capture.read()
        
        if not ret or self.stop:
            return 
        
        self.frame_count+=1
        if(self.frame_count%25!=1):
            return

        self.face_emo_frame = self.face_emo(self.image)
        self.image = self.face_emo_frame

        #print(self.image.shape())
        self.displayImage(self.image, self.encode_list, self.class_names, 1)
        
    def displayImage(self, image, encode_list, class_names, window=1):
        """
        :param image: frame from camera
        :param encode_list: known face encoding list
        :param class_names: known face names
        :param window: number of window
        :return:
        """
        #print(type(image))
        #print("bugging..")
        image = cv2.resize(image, (640, 480))
        try:
            image = self.face_emo(image)
        except Exception as e:
            print(e)
        qformat = QImage.Format_Indexed8
        if len(image.shape) == 3:
            if image.shape[2] == 4:
                qformat = QImage.Format_RGBA8888
            else:
                qformat = QImage.Format_RGB888
        outImage = QImage(image, image.shape[1], image.shape[0], image.strides[0], qformat)
        self.outImage = outImage.rgbSwapped()
        
        
        

        if window == 1:
            self.imgLabel.setPixmap(QPixmap.fromImage(self.outImage))
            self.imgLabel.setScaledContents(True)  
        self.create_bar()      
    
    @pyqtSlot()
    def face_emo(self, test_img):
		#face emotion
        #he = "jj"
        
        gray_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)

        faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)
        for (x, y, w, h) in faces_detected:
            cv2.rectangle(test_img, (x, y), (x+w, y+h), (255, 0, 0), thickness=7)
            # cropping region of interest i.e. face area from  image
            roi_gray=gray_img[y:y+w, x:x+h]
            roi_gray=cv2.resize(roi_gray, (48, 48))
            img_pixels = image.img_to_array(roi_gray)
            img_pixels = np.expand_dims(img_pixels, axis=0)
            img_pixels /= 255
            predictions = model.predict(img_pixels)

            # find max indexed array
            max_idx = np.argmax(predictions[0])

            emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')
            predicted_emotion = emotions[max_idx]
            if(max_idx==3):
                self.HappyCount+=1
            if(max_idx==1):
                self.DisgustCount+=1
            if(max_idx==2):
                self.FearCount+=1
            if(max_idx==0):
                self.AngryCount+=1
            if(max_idx==4):
                self.SadCount+=1
            if(max_idx==5):
                self.SurpriseCount+=1
            if(max_idx==6):
                self.NeutralCount+=1


            cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)



        self.write_test()

        return test_img
        
    def create_bar(self):
        #The QBarSet class represents a set of bars in the bar chart.
        # It groups several bars into a bar set
        
        
        

        set0 = QBarSet("Count")
        
        set0 << self.HappyCount << self.SadCount << self.AngryCount << self.FearCount << self.DisgustCount << self.SurpriseCount << self.NeutralCount 


        series = QBarSeries()
        series.append(set0)


        chart = QChart()
        chart.addSeries(series)
        chart.setTitle("Emotion")
        
        #chart.setAnimationOptions(QChart.SeriesAnimations)
        labelsFont = QFont()
        labelsFont.setPixelSize(12)
        #axisPen = QPen()
        #axisPen.setWidth(4);
        
        #series.setLinePen(axisPen)

        categories = ["Happy", "Sad", "Angry", "Fear", "Disgust", "Surprise", "Neutral"]
        axis = QBarCategoryAxis()
        axis.setLabelsFont(labelsFont);
        #axis.setLinePen(axisPen);
        axis.append(categories)
        chart.createDefaultAxes()
        chart.setAxisX(axis, series)
        #chart.getAxis('X').tickFont = font
        
        #chart.legend().font  = 2

        chart.legend().setVisible(True)
        chart.legend().setAlignment(Qt.AlignBottom)

        chartView = QChartView(chart)
        chartView.setRenderHint(QPainter.Antialiasing)

        self.graphicsView.setChart(chart)
        #self.graphicsView.setRenderHint(QtGui.QPainter.Antialiasing)
    @pyqtSlot()
    def write_test(self):
        
        text = "No count"
        count = 0

        if(self.HappyCount>count):
            text="Happy"
            count = self.HappyCount
        if(self.SadCount>count):
            text="Sad"
            count = self.SadCount
        if(self.FearCount>count):
            text="Fear"
            count = self.FearCount
        if(self.NeutralCount>count):
            text="Neutral"
            count = self.NeutalCount
        if(self.DisgustCount>count):
            text="Disgust"
            count = self.DisgustCount
        if(self.SurpriseCount>count):
            text="Surprise"
            count = self.SurpriseCount
        if(self.AngryCount>count):
            text="Angry"
            count = self.AngryCount
      
        self.result.setText("Result : "+text)

		
		
#import resource_rc


if __name__ == "__main__":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    OutputDialog = QtWidgets.QDialog()
    ui = Ui_OutputDialog()
    ui.setupUi(OutputDialog)
    OutputDialog.setWindowTitle("Face Emotion Detection")
    OutputDialog.show()
    sys.exit(app.exec_())
